# Settings for Transformer model.

# Common settings for DL models
include "configs/prediction_models/common/DLCommon.gin"

# Optimizer params
train_common.model = @TemporalFusionTransformer

optimizer/hyperparameter.class_to_tune = @Adam
optimizer/hyperparameter.weight_decay = 1e-6
optimizer/hyperparameter.lr = (1e-5, 3e-4)

# Encoder params
model/hyperparameter.class_to_tune = @TemporalFusionTransformer
model/hyperparameter.encoder_length = (1,14,"log-uniform", 2)
model/hyperparameter.hidden = (32, 256, "log-uniform", 2)
model/hyperparameter.num_classes = %NUM_CLASSES
model/hyperparameter.hidden = (32, 256, "log-uniform", 2)
model/hyperparameter.depth = (1, 3)
model/hyperparameter.dropout = (0.0, 0.4)
model/hyperparameter.dropout_att = (0.0, 0.4)
model/hyperparameter.n_heads = (1, 8, "log-uniform", 2)
model/hyperparameter.quantiles=[0.1, 0.5, 0.9]
model/hyperparameter.example_length=(1,14,"log-uniform", 2)


