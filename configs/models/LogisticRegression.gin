import gin.torch.external_configurables
import icu_benchmarks.models.wrappers
import icu_benchmarks.models.encoders
import icu_benchmarks.models.utils

preprocess.use_features = True

# Train params
train_common.model = @MLWrapper()

MLWrapper.model = @LogisticRegression()

model/hyperparameter.class_to_tune = @LogisticRegression
model/hyperparameter.solver = "saga"
model/hyperparameter.max_iter = 100000
model/hyperparameter.C = (1e-3, 1e1, "log-uniform")
model/hyperparameter.penalty = ["l1", "l2", "elasticnet"]
model/hyperparameter.l1_ratio = (0.0, 1.0)

tune_hyperparameters.scopes = ["model"]
tune_hyperparameters.n_initial_points = 10
tune_hyperparameters.n_calls = 100
tune_hyperparameters.folds_to_tune_on = 3
