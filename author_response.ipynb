{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c963b0-65d3-4dfe-81b7-d936d330c80b",
   "metadata": {},
   "source": [
    "## Author Response Period results and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b29eada-2f1a-4e5e-ad2f-6ccda3cd22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import metrics as mt\n",
    "import compute_KL as ckl\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee655b-e372-464a-9b5d-3343f4ae6d44",
   "metadata": {},
   "source": [
    "### Section 1: Original experiments values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b79cc6-342e-4b2f-905b-7a40f873bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_file = 'YAIB-cohorts/data/mortality24/eicu/above2000.txt'\n",
    "df = pd.read_csv(hospital_file, header=None)\n",
    "n = 12\n",
    "hospital_ids = df[0].values[:n]\n",
    "hospital_dict = {} \n",
    "for i in range(len(hospital_ids)):\n",
    "    hospital_dict[hospital_ids[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a9ff10-c15f-402a-b211-4616ef5ecf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hos=443\n",
    "# hospital\n",
    "incl_ground_truth = True\n",
    "hospital_dict = {} \n",
    "for i in range(len(hospital_ids)):\n",
    "    hospital_dict[hospital_ids[i]] = i\n",
    "    \n",
    "hos_ind = hospital_dict[hos]\n",
    "model = \"LogisticRegression\"\n",
    "n_avg = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-avg.npz\", allow_pickle=True)\n",
    "n_std = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-std.npz\", allow_pickle=True)\n",
    "dist_shift_avg = np.load(f\"results/dist_shift/{model}-n1500-avg.npz\", allow_pickle=True)\n",
    "dist_shift_std = np.load(f\"results/dist_shift/{model}-n1500-std.npz\", allow_pickle=True)\n",
    "sequential_best_avg = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-best-hospitals-avg.npz\", allow_pickle=True)\n",
    "sequential_best_std = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-best-hospitals-std.npz\", allow_pickle=True)\n",
    "sequential_worst_avg = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-worst-hospitals-avg.npz\", allow_pickle=True)\n",
    "sequential_worst_std = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-worst-hospitals-std.npz\", allow_pickle=True)\n",
    "mixture_avg = np.load(f\"results/sequential-n/{hos}/{hos}-mixture-{model}-avg.npz\", allow_pickle=True)\n",
    "mixture_std = np.load(f\"results/sequential-n/{hos}/{hos}-mixture-{model}-std.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079c4936-4dfc-4e43-aafc-a17962de8bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame.from_dict(n_avg['AUC'].item(), orient='index', columns=['AUC'])\n",
    "std_df = pd.DataFrame.from_dict(n_std['AUC'].item(), orient='index', columns=['std'])\n",
    "\n",
    "plot_df = pd.concat([plot_df, std_df], axis=1)\n",
    "new_df = plot_df.reset_index(names='n')\n",
    "new_df['train_hospital'] = hos\n",
    "\n",
    "best_df = pd.DataFrame.from_dict(sequential_best_avg['AUC'].item(), orient='index', columns=['Best3-AUC'])\n",
    "worst_df = pd.DataFrame.from_dict(sequential_worst_avg['AUC'].item(), orient='index', columns=['Worst3-AUC'])\n",
    "mixture_df = pd.DataFrame.from_dict(mixture_avg['AUC'].item(), orient='index', columns=['Mixture-AUC'])\n",
    "best_df_std = pd.DataFrame.from_dict(sequential_best_std['AUC'].item(), orient='index', columns=['Best3-std'])\n",
    "worst_df_std = pd.DataFrame.from_dict(sequential_worst_std['AUC'].item(), orient='index', columns=['Worst3-std'])\n",
    "mixture_df_std = pd.DataFrame.from_dict(mixture_std['AUC'].item(), orient='index', columns=['Mixture-std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61934231-c4e6-43a0-8610-a8844b1c9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.concat([best_df, worst_df, mixture_df, best_df_std, worst_df_std, mixture_df_std], axis=1)\n",
    "addition_df = plot_df.reset_index(names='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84f51f6-a457-4681-b470-fdca2118b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best3-AUC</th>\n",
       "      <th>Worst3-AUC</th>\n",
       "      <th>Mixture-AUC</th>\n",
       "      <th>Best3-std</th>\n",
       "      <th>Worst3-std</th>\n",
       "      <th>Mixture-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.754913</td>\n",
       "      <td>0.732681</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0.755354</td>\n",
       "      <td>0.719812</td>\n",
       "      <td>0.747519</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>0.764739</td>\n",
       "      <td>0.738016</td>\n",
       "      <td>0.752954</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.009281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Best3-AUC  Worst3-AUC  Mixture-AUC  Best3-std  Worst3-std  Mixture-std\n",
       "3000   0.754913    0.732681     0.743667   0.008487    0.010288     0.010278\n",
       "4500   0.755354    0.719812     0.747519   0.008113    0.009501     0.009649\n",
       "6000   0.764739    0.738016     0.752954   0.007506    0.009880     0.009281"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f9454c-b8bc-493d-b4b7-39cf82d492e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_ratio = np.sqrt(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bd6eb-9e9a-4e05-93d4-263ff3a05458",
   "metadata": {},
   "source": [
    "### Section 2: Extract new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54e565a8-bb38-4961-9084-4d2629fbe2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_n = 1000\n",
    "model = \"LogisticRegression\"\n",
    "n_avg = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-avg.npz\", allow_pickle=True)\n",
    "n_std = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-std.npz\", allow_pickle=True)\n",
    "sequential_best_avg = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-{model}-best-hospitals-avg.npz\", allow_pickle=True)\n",
    "sequential_best_std = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-{model}-best-hospitals-std.npz\", allow_pickle=True)\n",
    "sequential_worst_avg = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-{model}-worst-hospitals-avg.npz\", allow_pickle=True)\n",
    "sequential_worst_std = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-{model}-worst-hospitals-std.npz\", allow_pickle=True)\n",
    "mixture_avg = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-mixture-{model}-avg.npz\", allow_pickle=True)\n",
    "mixture_std = np.load(f\"results/sequential-n{file_n}/{hos}/{hos}-mixture-{model}-std.npz\", allow_pickle=True)\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict(n_avg['AUC'].item(), orient='index', columns=['AUC'])\n",
    "std_df = pd.DataFrame.from_dict(n_std['AUC'].item(), orient='index', columns=['std'])\n",
    "\n",
    "plot_df = pd.concat([plot_df, std_df], axis=1)\n",
    "new_df = plot_df.reset_index(names='n')\n",
    "new_df['train_hospital'] = hos\n",
    "\n",
    "best_df = pd.DataFrame.from_dict(sequential_best_avg['AUC'].item(), orient='index', columns=['Best3-AUC'])\n",
    "worst_df = pd.DataFrame.from_dict(sequential_worst_avg['AUC'].item(), orient='index', columns=['Worst3-AUC'])\n",
    "mixture_df = pd.DataFrame.from_dict(mixture_avg['AUC'].item(), orient='index', columns=['Mixture-AUC'])\n",
    "best_df_std = pd.DataFrame.from_dict(sequential_best_std['AUC'].item(), orient='index', columns=['Best3-std'])\n",
    "worst_df_std = pd.DataFrame.from_dict(sequential_worst_std['AUC'].item(), orient='index', columns=['Worst3-std'])\n",
    "mixture_df_std = pd.DataFrame.from_dict(mixture_std['AUC'].item(), orient='index', columns=['Mixture-std'])\n",
    "plot_df = pd.concat([best_df, worst_df, mixture_df, best_df_std, worst_df_std, mixture_df_std], axis=1)\n",
    "addition_df = plot_df.reset_index(names='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3c858c-7f07-450a-a7cb-dcec67d01475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best3-AUC</th>\n",
       "      <th>Worst3-AUC</th>\n",
       "      <th>Mixture-AUC</th>\n",
       "      <th>Best3-std</th>\n",
       "      <th>Worst3-std</th>\n",
       "      <th>Mixture-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.735563</td>\n",
       "      <td>0.709273</td>\n",
       "      <td>0.726154</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.745956</td>\n",
       "      <td>0.700069</td>\n",
       "      <td>0.737105</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>0.010062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>0.753337</td>\n",
       "      <td>0.735349</td>\n",
       "      <td>0.741432</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Best3-AUC  Worst3-AUC  Mixture-AUC  Best3-std  Worst3-std  Mixture-std\n",
       "2000   0.735563    0.709273     0.726154   0.007521    0.011729     0.009100\n",
       "3000   0.745956    0.700069     0.737105   0.007628    0.010716     0.010062\n",
       "4000   0.753337    0.735349     0.741432   0.007533    0.009567     0.009712"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47a605f8-ee5d-44eb-8f7e-1eccce70575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avg = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-avg.npz\", allow_pickle=True)\n",
    "n_std = np.load(f\"results/sequential-n/{hos}/{hos}-{model}-std.npz\", allow_pickle=True)\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict(n_avg['AUC'].item(), orient='index', columns=['AUC'])\n",
    "std_df = pd.DataFrame.from_dict(n_std['AUC'].item(), orient='index', columns=['std'])\n",
    "plot_df = pd.concat([plot_df, std_df], axis=1)\n",
    "new_df = plot_df.reset_index(names='n')\n",
    "new_df['train_hospital'] = hos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7da12b0-1cc9-450f-a618-374fb04fe318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>AUC</th>\n",
       "      <th>std</th>\n",
       "      <th>train_hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>0.662183</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800</td>\n",
       "      <td>0.711760</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.717573</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.725728</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.731079</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.737726</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n       AUC       std  train_hospital\n",
       "0   400  0.662183  0.012482             443\n",
       "1   800  0.711760  0.008971             443\n",
       "2  1000  0.717573  0.008739             443\n",
       "3  1200  0.725728  0.010076             443\n",
       "4  1500  0.731079  0.010628             443\n",
       "5  2000  0.737726  0.009233             443"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc2a34-c541-499b-a8d5-ec0621584233",
   "metadata": {},
   "source": [
    "## Score Function Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968cd87-c3b2-498e-bd1a-cf466f571728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "n = 12\n",
    "hospital_file = '/home/ubuntu/projects/more-data-more-problems/YAIB-cohorts/data/mortality24/eicu/above2000.txt'\n",
    "df = pd.read_csv(hospital_file, header=None)\n",
    "hospital_ids = df[0].values[:n]\n",
    "\n",
    "hospital_dict = {} \n",
    "for i in range(len(hospital_ids)):\n",
    "    hospital_dict[hospital_ids[i]] = i\n",
    "    \n",
    "#all_sizes = {} \n",
    "\n",
    "for max_size in [200, 100, 50]:\n",
    "    print(f\"calculating max size {max_size}\")\n",
    "    results_x = np.zeros((len(hospital_ids), len(hospital_ids))) \n",
    "    results_xy = np.zeros((len(hospital_ids), len(hospital_ids))) \n",
    "    for test_i, test_h in enumerate(hospital_ids): \n",
    "        for i, h in enumerate(hospital_ids): \n",
    "            hos = test_h\n",
    "            if h != hos: \n",
    "                x, y, xy = ckl.get_hospital(h, 'train', max_samples=max_size)\n",
    "                x2, y2, xy2 = ckl.get_hospital(hos, 'train', max_samples=max_size)\n",
    "                print(len(x))\n",
    "                scaler = StandardScaler()\n",
    "                logistic = LogisticRegression(max_iter=10000, tol=0.1)\n",
    "                pipe = Pipeline(steps=[(\"scaler\", scaler), (\"logistic\", logistic)])\n",
    "                \n",
    "                # X_train = np.concatenate((x, x2), axis=0)\n",
    "                # Y_train = np.concatenate((np.ones(len(x)), np.zeros(len(x2))), axis=0)\n",
    "                \n",
    "                # pipe.fit(X_train, Y_train)\n",
    "                \n",
    "                # x_val, _, _ = ckl.get_hospital(h, 'test')\n",
    "                # results_x[i, test_i] = pipe.predict_proba(x_val)[:, 1].mean()\n",
    "    \n",
    "                X_train = np.concatenate((xy, xy2), axis=0)\n",
    "                Y_train = np.concatenate((np.ones(len(xy)), np.zeros(len(xy2))), axis=0)\n",
    "                \n",
    "                pipe.fit(X_train, Y_train)\n",
    "                \n",
    "                _, _, xy_val = ckl.get_hospital(h, 'test')\n",
    "                results_xy[i, test_i] = pipe.predict_proba(xy_val)[:, 1].mean()\n",
    "    all_sizes[max_size] = results_xy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca4b2304-1468-4012-b5bb-3d9079fca378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 PearsonRResult(statistic=0.9940310253717729, pvalue=1.5755847404540598e-138)\n",
      "1000 PearsonRResult(statistic=0.9941845917355212, pvalue=2.4892243746403424e-139)\n",
      "800 PearsonRResult(statistic=0.9931834088285018, pvalue=1.9014749200001079e-134)\n",
      "500 PearsonRResult(statistic=0.994541062675264, pvalue=2.824247565532734e-141)\n",
      "200 PearsonRResult(statistic=0.9885471120845948, pvalue=1.617995144270007e-118)\n",
      "100 PearsonRResult(statistic=0.9762139673387682, pvalue=3.6175278953543356e-96)\n",
      "50 PearsonRResult(statistic=0.955518637991524, pvalue=3.505482822511442e-77)\n"
     ]
    }
   ],
   "source": [
    "ref = all_sizes[2000].flatten()\n",
    "for comp in [1500, 1000, 800, 500, 200, 100, 50]: \n",
    "    print(comp, pearsonr(ref, all_sizes[comp].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc59838-43ae-44d3-9ff9-699a64c027f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52891e85-0506-4558-bccd-ba446ea253ff",
   "metadata": {},
   "source": [
    "### Ground Truth Distribution Shift Hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd959cf0-fe25-4a37-827b-84abb6b4c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hos=443\n",
    "file_n = ''\n",
    "model = \"LogisticRegression\"\n",
    "n_avg = np.load(f\"YAIB/results/sequential-n/{hos}/{hos}-{model}-avg.npz\", allow_pickle=True)\n",
    "n_std = np.load(f\"YAIB/results/sequential-n/{hos}/{hos}-{model}-std.npz\", allow_pickle=True)\n",
    "sequential_best_avg = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-{model}-best-hospitals-gt-avg.npz\", allow_pickle=True)\n",
    "sequential_best_std = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-{model}-best-hospitals-gt-std.npz\", allow_pickle=True)\n",
    "sequential_worst_avg = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-{model}-worst-hospitals-gt-avg.npz\", allow_pickle=True)\n",
    "sequential_worst_std = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-{model}-worst-hospitals-gt-std.npz\", allow_pickle=True)\n",
    "mixture_avg = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-mixture-{model}-avg.npz\", allow_pickle=True)\n",
    "mixture_std = np.load(f\"YAIB/results/sequential-n{file_n}/{hos}/{hos}-mixture-{model}-std.npz\", allow_pickle=True)\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict(n_avg['AUC'].item(), orient='index', columns=['AUC'])\n",
    "std_df = pd.DataFrame.from_dict(n_std['AUC'].item(), orient='index', columns=['std'])\n",
    "\n",
    "plot_df = pd.concat([plot_df, std_df], axis=1)\n",
    "new_df = plot_df.reset_index(names='n')\n",
    "new_df['train_hospital'] = hos\n",
    "\n",
    "best_df = pd.DataFrame.from_dict(sequential_best_avg['AUC'].item(), orient='index', columns=['Best3-AUC'])\n",
    "worst_df = pd.DataFrame.from_dict(sequential_worst_avg['AUC'].item(), orient='index', columns=['Worst3-AUC'])\n",
    "mixture_df = pd.DataFrame.from_dict(mixture_avg['AUC'].item(), orient='index', columns=['Mixture-AUC'])\n",
    "best_df_std = pd.DataFrame.from_dict(sequential_best_std['AUC'].item(), orient='index', columns=['Best3-std'])\n",
    "worst_df_std = pd.DataFrame.from_dict(sequential_worst_std['AUC'].item(), orient='index', columns=['Worst3-std'])\n",
    "mixture_df_std = pd.DataFrame.from_dict(mixture_std['AUC'].item(), orient='index', columns=['Mixture-std'])\n",
    "plot_df = pd.concat([best_df, worst_df, mixture_df, best_df_std, worst_df_std, mixture_df_std], axis=1)\n",
    "addition_df = plot_df.reset_index(names='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106caab4-7e42-4982-9872-faba6a4e5444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best3-AUC</th>\n",
       "      <th>Worst3-AUC</th>\n",
       "      <th>Mixture-AUC</th>\n",
       "      <th>Best3-std</th>\n",
       "      <th>Worst3-std</th>\n",
       "      <th>Mixture-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.754913</td>\n",
       "      <td>0.732681</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.010288</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>0.765146</td>\n",
       "      <td>0.718710</td>\n",
       "      <td>0.747519</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>0.743729</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.752954</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.009281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Best3-AUC  Worst3-AUC  Mixture-AUC  Best3-std  Worst3-std  Mixture-std\n",
       "3000   0.754913    0.732681     0.743667   0.008487    0.010288     0.010278\n",
       "4500   0.765146    0.718710     0.747519   0.009459    0.012256     0.009649\n",
       "6000   0.743729    0.719298     0.752954   0.008696    0.009804     0.009281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd4742-2488-4d2d-9dc5-e6a30b39efa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
